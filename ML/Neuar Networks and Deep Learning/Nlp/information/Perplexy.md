#NLP #Metrics
**Перплексия** в теории информации  — [безразмерная величина](https://ru.wikipedia.org/wiki/%D0%91%D0%B5%D0%B7%D1%80%D0%B0%D0%B7%D0%BC%D0%B5%D1%80%D0%BD%D0%B0%D1%8F_%D0%B2%D0%B5%D0%BB%D0%B8%D1%87%D0%B8%D0%BD%D0%B0 "Безразмерная величина"), мера того, насколько хорошо [распределение вероятностей](https://ru.wikipedia.org/wiki/%D0%A0%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5_%D0%B2%D0%B5%D1%80%D0%BE%D1%8F%D1%82%D0%BD%D0%BE%D1%81%D1%82%D0%B5%D0%B9 "Распределение вероятностей") предсказывает выборку. Перплексия может использоваться для сравнения качества статистических моделей. Низкий показатель перплексии указывает на то, что распределение вероятности хорошо предсказывает выборку.



Формула для использования в nlp
$PP(w)= \exp (-\frac{1}{k}\sum_{i=0}^{k}\log P(\mathrm{w}_{i}^{}|\mathrm{w}_{i-1}^{} ...,\mathrm{w}_{0}^{}) )$

 




![3:38](https://youtu.be/DHuRg6iO6FU?feature=shared&t=218)

https://ru.wikipedia.org/wiki/%D0%9F%D0%B5%D1%80%D0%BF%D0%BB%D0%B5%D0%BA%D1%81%D0%B8%D1%8F
